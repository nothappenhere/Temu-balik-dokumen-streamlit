{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skor kemiripan dengan query - Nama file:\n",
      "1.780818812544124: documents/manusia.txt\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import sys\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "\n",
    "#misal kita punya database dokumnet dengan id angka (0, 2, 5....)\n",
    "document_filenames = {\n",
    "    0: \"documents/bapak perjuangan.txt\",\n",
    "    1: \"documents/cara cepat pintar.txt\",\n",
    "    2: \"documents/manusia.txt\",\n",
    "    5: \"documents/dok1.docx\",\n",
    "    7: \"documents/jago coding.pdf\",\n",
    "    3: \"documents/tomat buah.txt\"\n",
    "}\n",
    "\n",
    "# Ukuran korpus\n",
    "N = len(document_filenames)\n",
    "\n",
    "# dictionary: menyimpan semua istilah (kata) dalam korpus dokumen\n",
    "dictionary = set()\n",
    "\n",
    "# postings: menyimpan daftar posting untuk setiap istilah\n",
    "postings = defaultdict(dict)\n",
    "\n",
    "# document_frequency: menyimpan jumlah dokumen yang mengandung istilah tertentu\n",
    "document_frequency = defaultdict(int)\n",
    "\n",
    "# length: menyimpan panjang Euclidean dari vektor dokumen\n",
    "length = defaultdict(float)\n",
    "\n",
    "# Daftar karakter yang akan dihapus saat tokenisasi\n",
    "characters = \" .,!#$%^&*();:\\n\\t\\\\\\\"?!{}[]<>\"\n",
    "\n",
    "def main():\n",
    "    initialize_terms_and_postings()\n",
    "    initialize_document_frequencies()\n",
    "    initialize_lengths()\n",
    "    while True:\n",
    "        do_search()\n",
    "\n",
    "def initialize_terms_and_postings():\n",
    "    \"\"\"Memproses setiap dokumen, menambahkan istilah baru ke dictionary,\n",
    "    dan memperbarui daftar posting.\"\"\"\n",
    "    global dictionary, postings\n",
    "    for id, filepath in document_filenames.items():\n",
    "        document = read_document(filepath)\n",
    "        terms = tokenize(document)\n",
    "        unique_terms = set(terms)\n",
    "        dictionary = dictionary.union(unique_terms)\n",
    "        for term in unique_terms:\n",
    "            postings[term][id] = terms.count(term)\n",
    "\n",
    "def read_document(filepath):\n",
    "    \"\"\"Membaca isi dokumen berdasarkan format file.\"\"\"\n",
    "    ext = Path(filepath).suffix.lower()\n",
    "    if ext == \".txt\":\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    elif ext == \".pdf\":\n",
    "        return read_pdf(filepath)\n",
    "    elif ext == \".docx\":\n",
    "        return read_docx(filepath)\n",
    "    else:\n",
    "        print(f\"Format file {ext} tidak didukung.\")\n",
    "        return \"\"\n",
    "\n",
    "def read_pdf(filepath):\n",
    "    \"\"\"Membaca isi dokumen PDF.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def read_docx(filepath):\n",
    "    \"\"\"Membaca isi dokumen DOCX.\"\"\"\n",
    "    doc = Document(filepath)\n",
    "    return \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
    "\n",
    "def tokenize(document):\n",
    "    \"\"\"Mengembalikan daftar istilah setelah tokenisasi dan normalisasi.\"\"\"\n",
    "    terms = document.lower().split()\n",
    "    return [term.strip(characters) for term in terms]\n",
    "\n",
    "def initialize_document_frequencies():\n",
    "    \"\"\"Menghitung jumlah dokumen yang mengandung setiap istilah.\"\"\"\n",
    "    global document_frequency\n",
    "    for term in dictionary:\n",
    "        document_frequency[term] = len(postings[term])\n",
    "\n",
    "def initialize_lengths():\n",
    "    \"\"\"Menghitung panjang vektor untuk setiap dokumen.\"\"\"\n",
    "    global length\n",
    "    for id in document_filenames:\n",
    "        l = 0\n",
    "        for term in dictionary:\n",
    "            l += imp(term, id)**2\n",
    "        length[id] = math.sqrt(l)\n",
    "\n",
    "def imp(term, id):\n",
    "    \"\"\"Mengembalikan bobot istilah dalam dokumen tertentu.\"\"\"\n",
    "    if id in postings[term]:\n",
    "        return postings[term][id] * inverse_document_frequency(term)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def inverse_document_frequency(term):\n",
    "    \"\"\"Mengembalikan frekuensi dokumen terbalik (IDF) dari istilah.\"\"\"\n",
    "    if term in dictionary:\n",
    "        return math.log(N / document_frequency[term], 2)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def do_search():\n",
    "    \"\"\"Meminta input kueri pengguna dan menampilkan dokumen yang relevan.\"\"\"\n",
    "    query = tokenize(input(\"Search query >> \"))\n",
    "    if query == []:\n",
    "        sys.exit()\n",
    "    relevant_document_ids = intersection(\n",
    "        [set(postings[term].keys()) for term in query if term in postings]\n",
    "    )\n",
    "    if not relevant_document_ids:\n",
    "        print(\"Tidak ada dokumen yang cocok dengan kueri.\")\n",
    "    else:\n",
    "        scores = sorted(\n",
    "            [(id, similarity(query, id)) for id in relevant_document_ids],\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        print(\"Skor kemiripan dengan query - Nama file:\")\n",
    "        for id, score in scores:\n",
    "            print(f\"{score}: {document_filenames[id]}\")\n",
    "\n",
    "def intersection(sets):\n",
    "    \"\"\"Mengembalikan irisan dari semua set.\"\"\"\n",
    "    return reduce(set.intersection, sets) if sets else set()\n",
    "\n",
    "def similarity(query, id):\n",
    "    \"\"\"Menghitung kesamaan kosinus antara kueri dan dokumen tertentu.\"\"\"\n",
    "    similarity = 0.0\n",
    "    for term in query:\n",
    "        if term in dictionary:\n",
    "            similarity += inverse_document_frequency(term) * imp(term, id)\n",
    "    similarity = similarity / length[id] if length[id] > 0 else 0.0\n",
    "    return similarity\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
